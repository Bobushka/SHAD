{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week_3 Assignment_2: Анализ текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/programming/NdyLO/analiz-tiekstov\n",
    "\n",
    "Данное задание основано на материалах лекций по методу опорных векторов.\n",
    "\n",
    "#### Вы научитесь:\n",
    "- находить оптимальные параметры для метода опорных векторов\n",
    "- работать с текстовыми данными\n",
    "\n",
    "#### Введение\n",
    "Метод опорных векторов (Support Vector Machine, SVM) — один из видов линейных классификаторов. Функционал, который он оптимизирует, направлен на максимизацию ширины разделяющей полосы между классами. Из теории статистического обучения известно, что эта ширина тесно связана с обобщающей способностью алгоритма, а ее максимизация позволяет бороться с переобучением.\n",
    "\n",
    "Одна из причин популярности линейных методов заключается в том, что они хорошо работают на разреженных данных. Так называются выборки с большим количеством признаков, где на каждом объекте большинство признаков равны нулю. Разреженные данные возникают, например, при работе с текстами. Дело в том, что текст удобно кодировать с помощью \"мешка слов\" — формируется столько признаков, сколько всего уникальных слов встречается в текстах, и значение каждого признака равно числу вхождений в документ соответствующего слова. Ясно, что общее число различных слов в наборе текстов может достигать десятков тысяч, и при этом лишь небольшая их часть будет встречаться в одном конкретном тексте.\n",
    "\n",
    "Можно кодировать тексты хитрее, и записывать не количество вхождений слова в текст, а [TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF). Это показатель, который равен произведению двух чисел: TF (term frequency) и IDF (inverse document frequency). Первая равна отношению числа вхождений слова в документ к общей длине документа. Вторая величина зависит от того, в скольки документах выборки встречается это слово. Чем больше таких документов, тем меньше IDF. Таким образом, TF-IDF будет иметь высокое значение для тех слов, которые много раз встречаются в данном документе, и редко встречаются в остальных.\n",
    "\n",
    "#### Данные\n",
    "Как мы уже говорили выше, линейные методы часто применяются для решения различных задач анализа текстов. В этом задании мы применим метод опорных векторов для определения того, к какой из тематик относится новость: атеизм или космос.\n",
    "\n",
    "#### Реализация в Scikit-Learn\n",
    "Для начала вам потребуется загрузить данные. В этом задании мы воспользуемся одним из датасетов, доступных в scikit-learn'е — 20 newsgroups. Для этого нужно воспользоваться модулем datasets:\n",
    "\n",
    "    from sklearn import datasets\n",
    "\n",
    "    newsgroups = datasets.fetch_20newsgroups(\n",
    "                    subset='all', \n",
    "                    categories=['alt.atheism', 'sci.space']\n",
    "             )\n",
    "После выполнения этого кода массив с текстами будет находиться в поле newsgroups.data, номер класса — в поле newsgroups.target.\n",
    "\n",
    "Одна из сложностей работы с текстовыми данными состоит в том, что для них нужно построить числовое представление. Одним из способов нахождения такого представления является вычисление TF-IDF. В Scikit-Learn это реализовано в классе [sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Преобразование обучающей выборки нужно делать с помощью функции fit_transform, тестовой — с помощью transform.\n",
    "\n",
    "Реализация SVM-классификатора находится в классе [sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=sklearn%20svm%20svc#sklearn.svm.SVC). Веса каждого признака у обученного классификатора хранятся в поле coef_. Чтобы понять, какому слову соответствует i-й признак, можно воспользоваться методом get_feature_names() у TfidfVectorizer:\n",
    "\n",
    "    feature_mapping = vectorizer.get_feature_names()\n",
    "    print feature_mapping[i]\n",
    "\n",
    "Подбор параметров удобно делать с помощью класса [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=sklearn%20model_selection%20gridsearchcv#sklearn.model_selection.GridSearchCV). Пример использования:\n",
    "\n",
    "    grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "    clf = svm.SVC(kernel='linear', random_state=241)\n",
    "    gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "Первым аргументом в GridSearchCV передается классификатор, для которого будут подбираться значения параметров, вторым — словарь (dict), задающий сетку параметров для перебора. После того, как перебор окончен, можно проанализировать значения качества для всех значений параметров и выбрать наилучший вариант:\n",
    "\n",
    "    for a in gs.grid_scores_:\n",
    "        # a.mean_validation_score — оценка качества по кросс-валидации\n",
    "        # a.parameters — значения параметров\n",
    "\n",
    "#### Инструкция по выполнению\n",
    "1. Загрузите объекты из новостного датасета 20 newsgroups, относящиеся к категориям \"космос\" и \"атеизм\" (инструкция приведена выше). Обратите внимание, что загрузка данных может занять несколько минут\n",
    "2. Вычислите TF-IDF-признаки для всех текстов. Обратите внимание, что в этом задании мы предлагаем вам вычислить TF-IDF по **всем** данным. При таком подходе получается, что признаки на обучающем множестве используют информацию из тестовой выборки — но такая ситуация вполне законна, поскольку мы не используем значения целевой переменной из теста. На практике нередко встречаются ситуации, когда признаки объектов тестовой выборки известны на момент обучения, и поэтому можно ими пользоваться при обучении алгоритма.\n",
    "3. Подберите минимальный лучший параметр C из множества [10^-5, 10^-4, ... 10^4, 10^5] для SVM с линейным ядром (kernel='linear') при помощи кросс-валидации по 5 блокам. Укажите параметр random_state=241 и для SVM, и для KFold. В качестве меры качества используйте долю верных ответов (accuracy).\n",
    "4. Обучите SVM по всей выборке с оптимальным параметром C, найденным на предыдущем шаге.\n",
    "5. Найдите 10 слов с наибольшим абсолютным значением веса (веса хранятся в поле coef_ у svm.SVC). Они являются ответом на это задание. Укажите эти слова через запятую или пробел, в нижнем регистре, в лексикографическом порядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ответы на вопросы задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузите объекты из новостного датасета\n",
    "относящиеся к категориям \"космос\" и \"атеизм\" (инструкция приведена выше). Обратите внимание, что загрузка данных может занять несколько минут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "newsgroups = datasets.fetch_20newsgroups(\n",
    "                    subset='all', \n",
    "                    categories=['alt.atheism', 'sci.space']\n",
    "             )\n",
    "\n",
    "data = newsgroups.data\n",
    "y = newsgroups.target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1786"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Вычислите TF-IDF-признаки для всех текстов\n",
    "Обратите внимание, что в этом задании мы предлагаем вам вычислить TF-IDF по всем данным. При таком подходе получается, что признаки на обучающем множестве используют информацию из тестовой выборки — но такая ситуация вполне законна, поскольку мы не используем значения целевой переменной из теста. На практике нередко встречаются ситуации, когда признаки объектов тестовой выборки известны на момент обучения, и поэтому можно ими пользоваться при обучении алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1786, 28382)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as tv\n",
    "vectorizer = tv()\n",
    "X = vectorizer.fit_transform(data)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Подберите минимальный лучший параметр C\n",
    "из множества [10^-5, 10^-4, ... 10^4, 10^5] для SVM с линейным ядром (kernel='linear') при помощи кросс-валидации по 5 блокам. Укажите параметр random_state=241 и для SVM, и для KFold. В качестве меры качества используйте долю верных ответов (accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "хорошая объяснялка в помощь: [тыц](https://vc.ru/ml/147132-kak-avtomaticheski-podobrat-parametry-dlya-modeli-mashinnogo-obucheniya-ispolzuem-gridsearchcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV as GSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=241, shuffle=True),\n",
       "             estimator=SVC(kernel='linear', random_state=241),\n",
       "             param_grid={'C': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04, 1.e+05])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "clf = SVC(kernel='linear', random_state=241)\n",
    "gs = GSCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994400895856663"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X,y)    # смотрим какая у нас получилась точность на оптимальном параметре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_  # смотрим значение оптимального параметра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.320137</td>\n",
       "      <td>0.177012</td>\n",
       "      <td>0.901082</td>\n",
       "      <td>0.040442</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'C': 1e-05}</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.501401</td>\n",
       "      <td>0.565826</td>\n",
       "      <td>0.552636</td>\n",
       "      <td>0.028124</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.258248</td>\n",
       "      <td>0.079198</td>\n",
       "      <td>0.876305</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.501401</td>\n",
       "      <td>0.565826</td>\n",
       "      <td>0.552636</td>\n",
       "      <td>0.028124</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.411352</td>\n",
       "      <td>0.171161</td>\n",
       "      <td>0.887359</td>\n",
       "      <td>0.020671</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.501401</td>\n",
       "      <td>0.565826</td>\n",
       "      <td>0.552636</td>\n",
       "      <td>0.028124</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.271040</td>\n",
       "      <td>0.057098</td>\n",
       "      <td>0.897252</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.544693</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.501401</td>\n",
       "      <td>0.565826</td>\n",
       "      <td>0.552636</td>\n",
       "      <td>0.028124</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.008503</td>\n",
       "      <td>0.309560</td>\n",
       "      <td>0.819140</td>\n",
       "      <td>0.098440</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.958101</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.950164</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.654424</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>0.439559</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>0.993280</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.634081</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.436151</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>0.993280</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.634955</td>\n",
       "      <td>0.037586</td>\n",
       "      <td>0.430956</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100.0}</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>0.993280</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.695803</td>\n",
       "      <td>0.106676</td>\n",
       "      <td>0.454302</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 1000.0}</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>0.993280</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.651695</td>\n",
       "      <td>0.050469</td>\n",
       "      <td>0.440348</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 10000.0}</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>0.993280</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.126592</td>\n",
       "      <td>0.905079</td>\n",
       "      <td>0.461685</td>\n",
       "      <td>0.058501</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 100000.0}</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>0.993280</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        3.320137      0.177012         0.901082        0.040442   1e-05   \n",
       "1        3.258248      0.079198         0.876305        0.007541  0.0001   \n",
       "2        3.411352      0.171161         0.887359        0.020671   0.001   \n",
       "3        3.271040      0.057098         0.897252        0.017531    0.01   \n",
       "4        3.008503      0.309560         0.819140        0.098440     0.1   \n",
       "5        1.654424      0.022544         0.439559        0.016354       1   \n",
       "6        1.634081      0.032000         0.436151        0.008409      10   \n",
       "7        1.634955      0.037586         0.430956        0.011965     100   \n",
       "8        1.695803      0.106676         0.454302        0.024866    1000   \n",
       "9        1.651695      0.050469         0.440348        0.009373   10000   \n",
       "10       2.126592      0.905079         0.461685        0.058501  100000   \n",
       "\n",
       "             params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0      {'C': 1e-05}           0.544693           0.579832           0.571429   \n",
       "1     {'C': 0.0001}           0.544693           0.579832           0.571429   \n",
       "2      {'C': 0.001}           0.544693           0.579832           0.571429   \n",
       "3       {'C': 0.01}           0.544693           0.579832           0.571429   \n",
       "4        {'C': 0.1}           0.958101           0.949580           0.957983   \n",
       "5        {'C': 1.0}           0.994413           0.985994           1.000000   \n",
       "6       {'C': 10.0}           0.994413           0.985994           1.000000   \n",
       "7      {'C': 100.0}           0.994413           0.985994           1.000000   \n",
       "8     {'C': 1000.0}           0.994413           0.985994           1.000000   \n",
       "9    {'C': 10000.0}           0.994413           0.985994           1.000000   \n",
       "10  {'C': 100000.0}           0.994413           0.985994           1.000000   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.501401           0.565826         0.552636        0.028124   \n",
       "1            0.501401           0.565826         0.552636        0.028124   \n",
       "2            0.501401           0.565826         0.552636        0.028124   \n",
       "3            0.501401           0.565826         0.552636        0.028124   \n",
       "4            0.935574           0.949580         0.950164        0.008218   \n",
       "5            0.991597           0.994398         0.993280        0.004552   \n",
       "6            0.991597           0.994398         0.993280        0.004552   \n",
       "7            0.991597           0.994398         0.993280        0.004552   \n",
       "8            0.991597           0.994398         0.993280        0.004552   \n",
       "9            0.991597           0.994398         0.993280        0.004552   \n",
       "10           0.991597           0.994398         0.993280        0.004552   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 8  \n",
       "1                 8  \n",
       "2                 8  \n",
       "3                 8  \n",
       "4                 7  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 1  \n",
       "8                 1  \n",
       "9                 1  \n",
       "10                1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(gs.cv_results_)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Обучите SVM по всей выборке с оптимальным параметром C, найденным на предыдущем шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=241)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C=1.0, kernel='linear', random_state=241)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Найдите 10 слов с наибольшим абсолютным значением веса\n",
    "(веса хранятся в поле coef_ у svm.SVC). Они являются ответом на это задание. Укажите эти слова через запятую или пробел, в нижнем регистре, в лексикографическом порядке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 1.25468995, 1.9203794 ,\n",
       "        2.66316479]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.sort(np.absolute(clf.coef_.toarray()))  # отсортированные по модулю веса слов\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7801, 21437,  9144, ...,  5088, 12871, 24019]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = np.argsort(np.absolute(clf.coef_.toarray()))  # отсортированные по модулю весов индексы слов\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22936, 15606,  5776, 21850, 23673, 17802,  5093,  5088, 12871,\n",
       "       24019])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_indexes = np.array(indexes[0,-10:], dtype=int)  # последние 10 индексов\n",
    "top_10_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atheism' 'atheists' 'bible' 'god' 'keith' 'moon' 'religion' 'sci' 'sky'\n",
      " 'space']\n"
     ]
    }
   ],
   "source": [
    "list = [vectorizer.get_feature_names()[i] for i in top_10_indexes]  # переводим признаки в слова\n",
    "print(np.sort(list))  # выводим топ-10 слов (по возрастанию индекса, как в чартовой дюжине MTV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
